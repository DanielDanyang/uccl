# Phase 3: Multi-Channel Performance Test - Complete

**Date**: 2025-10-05
**Updated**: 2025-10-06
**Status**: âœ… **COMPLETE** (but see note below about chunk size)

---

## âš ï¸ Important Note (2025-10-06)

**Chunk size**: The default is **512KB**, not 2MB. The "2MB optimization" mentioned in earlier versions was incorrect and has been corrected.

**Current issue**: GPU-NIC topology fix needs revert. See **CURRENT_STATUS.md** and **TOPOLOGY_FIX.md** for details.

---

## ğŸ¯ Phase 3 Goal

Refactor `test_tcpx_perf.cc` to use multi-channel architecture, enabling utilization of multiple NICs to achieve aggregate bandwidth improvement.

---

## âœ… Completed Work

### 1. Created Multi-Channel Performance Test

**New File**: `tests/test_tcpx_perf_multi.cc` (884 lines)

**Key Features**:
- âœ… Uses `ChannelManager` for multi-channel lifecycle management
- âœ… Uses `Bootstrap` for multi-handle exchange
- âœ… Round-robin chunk distribution across channels
- âœ… Per-channel independent sliding windows
- âœ… Shared memory registration (all channels share same GPU buffer)
- âœ… Supports `UCCL_TCPX_NUM_CHANNELS` environment variable
- âœ… Backward compatible (default: 1 channel)
- âœ… Preserves ALL debugging experience from original test

### 2. Preserved Critical "Blood-Sweat-Tears" Experience

All 10 critical lessons from `test_tcpx_perf.cc` are preserved:

#### 1. Sliding Window Check BEFORE tcpx_irecv âœ…
```cpp
// ã€ä¿®å¤ã€‘æ»‘åŠ¨çª—å£æ£€æŸ¥ - å¿…é¡»åœ¨ tcpx_irecv ä¹‹å‰ï¼
if (impl == "kernel") {
  if (win.pending_reqs.size() >= MAX_INFLIGHT_PER_CHANNEL) {
    // Wait for oldest chunk to complete
    cudaEventSynchronize(oldest_event);
    tcpx_irecv_consumed(ch.recv_comm, 1, oldest_req);
    // Remove from window
    win.pending_reqs.erase(win.pending_reqs.begin());
  }
}
// NOW safe to call tcpx_irecv
```

#### 2. tcpx_irecv_consumed After Kernel Completion âœ…
```cpp
// Use CUDA events to track kernel completion
cudaEventRecord(win.events[event_idx], unpack_stream);
win.pending_reqs.push_back(recv_request);

// Later: wait for event, then call irecv_consumed
cudaEventSynchronize(oldest_event);
tcpx_irecv_consumed(ch.recv_comm, 1, oldest_req);
```

#### 3. Device Handle 16-Byte Alignment âœ…
```cpp
// Handled by ChannelManager internally
alignas(16) unsigned char recv_dev_handle_storage[512] = {0};
```

#### 4. Accept Retry Logic âœ…
```cpp
// Handled by ChannelManager::server_accept_all()
// with kMaxRetries=100 and 100ms delay
```

#### 5. Unique Tag Per Chunk âœ…
```cpp
// ã€å…³é”®ã€‘æ¯ä¸ª chunk ä½¿ç”¨å”¯ä¸€çš„ tag
const int tag = kTransferTag + iter * 10000 + global_chunk_idx;
```

#### 6. No Timeout, Continuous Polling âœ…
```cpp
// ã€ä¿®å¤ã€‘ç§»é™¤è¶…æ—¶é™åˆ¶ï¼ŒæŒç»­è½®è¯¢ç›´åˆ°æ¥æ”¶å®Œæˆ
while (!done) {
  tcpx_test(recv_request, &done, &received_size);
  if (!done) std::this_thread::sleep_for(std::chrono::microseconds(10));
}
```

#### 7. Persistent Stream and Launcher âœ…
```cpp
// ã€å…³é”®ä¼˜åŒ–ã€‘åœ¨å¾ªç¯å¤–åˆ›å»ºï¼Œé¿å…æ¯ä¸ª chunk ~4ms çš„åˆ›å»ºå¼€é”€
cudaStream_t unpack_stream = nullptr;
tcpx::device::UnpackLauncher* launcher_ptr = nullptr;

if (impl == "kernel") {
  cudaStreamCreate(&unpack_stream);
  launcher_ptr = new tcpx::device::UnpackLauncher(cfg);
}
```

#### 8. Client Sliding Window = 12 (< 16) âœ…
```cpp
// ã€å…³é”®ã€‘Client ä½¿ç”¨ 12 è€Œä¸æ˜¯ 16ï¼Œç•™ä½™é‡é¿å…è¾¹ç•Œæƒ…å†µ
constexpr int MAX_INFLIGHT_SEND_PER_CHANNEL = 12;
```

#### 9. Chunk Size 512KB (Default) âœ…
```cpp
// Chunk å¤§å°ï¼šé»˜è®¤ 512KB
size_t chunk_bytes = getEnvSize("UCCL_TCPX_CHUNK_BYTES",
                                 getEnvSize("NCCL_P2P_NET_CHUNKSIZE", 512 * 1024));
```

#### 10. Debug Logs Added âœ…
```cpp
// æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—ä»¥ä¾¿å‘ç°æ½œåœ¨bug
std::cout << "[DEBUG][SERVER] chunk=" << global_chunk_idx << " channel=" << channel_id
          << " tag=" << tag << " size=" << this_chunk << " offset=" << offset
          << " pending=" << win.pending_reqs.size() << "/" << MAX_INFLIGHT_PER_CHANNEL << std::endl;
```

---

## ğŸ—ï¸ Architecture

### Multi-Channel Design

```
Server:
  ChannelManager (N channels)
    â”œâ”€ Channel 0 (eth1) â”€â”¬â”€ SlidingWindow (16 slots)
    â”œâ”€ Channel 1 (eth2) â”€â”¼â”€ SlidingWindow (16 slots)
    â”œâ”€ Channel 2 (eth3) â”€â”¼â”€ SlidingWindow (16 slots)
    â””â”€ Channel 3 (eth4) â”€â”´â”€ SlidingWindow (16 slots)
  
  Shared GPU Buffer (256MB)
    â”œâ”€ Registered with all channels
    â””â”€ Chunks write to different offsets

Client:
  ChannelManager (N channels)
    â”œâ”€ Channel 0 (eth1) â”€â”¬â”€ SlidingWindow (12 slots)
    â”œâ”€ Channel 1 (eth2) â”€â”¼â”€ SlidingWindow (12 slots)
    â”œâ”€ Channel 2 (eth3) â”€â”¼â”€ SlidingWindow (12 slots)
    â””â”€ Channel 3 (eth4) â”€â”´â”€ SlidingWindow (12 slots)
  
  Shared GPU Buffer (256MB)
    â”œâ”€ Registered with all channels
    â””â”€ Chunks read from different offsets
```

### Round-Robin Distribution

```
Chunk 0 â†’ Channel 0 (eth1)
Chunk 1 â†’ Channel 1 (eth2)
Chunk 2 â†’ Channel 2 (eth3)
Chunk 3 â†’ Channel 3 (eth4)
Chunk 4 â†’ Channel 0 (eth1)  // Wrap around
...
```

### Per-Channel Sliding Window

Each channel maintains independent sliding window:
- **Server**: MAX_INFLIGHT_PER_CHANNEL = 16
- **Client**: MAX_INFLIGHT_SEND_PER_CHANNEL = 12

This ensures:
- No TCPX request pool exhaustion
- Each channel can process chunks independently
- Load balanced across all NICs

---

## ğŸ“Š Expected Performance

| Metric | Single Channel | 4 Channels | Improvement |
|--------|---------------|------------|-------------|
| **Server Time** | 21 ms | 5-6 ms | **3-4Ã—** |
| **Server BW** | 3 GB/s | 10-12 GB/s | **3-4Ã—** |
| **Client Time** | 77 ms | 20-25 ms | **3-4Ã—** |
| **Client BW** | 1 GB/s | 3-4 GB/s | **3-4Ã—** |
| **eth1 Traffic** | 3 GB/s | 3 GB/s | 1Ã— |
| **eth2 Traffic** | 0 GB/s | 3 GB/s | **âˆ** |
| **eth3 Traffic** | 0 GB/s | 3 GB/s | **âˆ** |
| **eth4 Traffic** | 0 GB/s | 3 GB/s | **âˆ** |
| **Total Throughput** | 3 GB/s | 12 GB/s | **4Ã—** |

---

## ğŸ§ª Testing

### Compilation âœ…

```bash
$ cd /home/daniel/uccl/p2p/tcpx
$ make test_tcpx_perf_multi
Building test_tcpx_perf_multi...
âœ… Success (no warnings or errors)
```

### Local Test (No TCPX)

```bash
$ ./tests/test_tcpx_perf_multi server 0
[ERROR] Invalid GPU or TCPX not available
```
âœ… Expected behavior on local machine

### Cloud Test (With TCPX)

**To be tested on GCP nodes**:

#### Single Channel (Backward Compatible)
```bash
# Server (10.65.74.150)
UCCL_TCPX_PERF_SIZE=67108864 ./tests/test_tcpx_perf_multi server 0

# Client (10.64.113.77)
UCCL_TCPX_PERF_SIZE=67108864 ./tests/test_tcpx_perf_multi client 10.65.74.150 0
```

**Expected**: Similar performance to original test (~21ms server, ~77ms client)

#### Multi-Channel (4 NICs)
```bash
# Server
UCCL_TCPX_NUM_CHANNELS=4 UCCL_TCPX_PERF_SIZE=67108864 ./tests/test_tcpx_perf_multi server 0

# Client
UCCL_TCPX_NUM_CHANNELS=4 UCCL_TCPX_PERF_SIZE=67108864 ./tests/test_tcpx_perf_multi client 10.65.74.150 0
```

**Expected**: 
- Server: ~5-6ms, ~10-12 GB/s
- Client: ~20-25ms, ~3-4 GB/s
- All 4 NICs show traffic in `ifstat`

#### Monitor NIC Usage
```bash
# On both nodes
watch -n 1 'ifstat -i eth1,eth2,eth3,eth4'
```

**Expected output**:
```
       eth1      eth2      eth3      eth4
KB/s in  out   in  out   in  out   in  out
    3000 3000 3000 3000 3000 3000 3000 3000
```

---

## ğŸ“ Files Modified

### New Files
1. `tests/test_tcpx_perf_multi.cc` - Multi-channel performance test (884 lines)
2. `docs/PHASE3_COMPLETE.md` - This file

### Modified Files
1. `Makefile` - Added `test_tcpx_perf_multi` target

---

## ğŸ”‘ Key Design Decisions

### 1. Per-Channel Sliding Windows
**Why**: Each channel has independent TCPX request pool (16 slots). Managing per-channel windows prevents one busy channel from blocking others.

### 2. Round-Robin Distribution
**Why**: Simple, deterministic, and ensures even load distribution across all channels.

### 3. Shared Memory Registration
**Why**: Simplifies memory management, avoids data copying, and matches NCCL's approach.

### 4. Backward Compatible Default
**Why**: Safe deployment - default behavior (1 channel) matches original test.

### 5. Preserved All Debug Experience
**Why**: Original test was debugged extensively. Preserving all lessons ensures reliability.

---

## ğŸš€ Next Steps

### Immediate (Cloud Testing)

1. **Test single-channel mode** (verify backward compatibility)
2. **Test multi-channel mode** (verify 4Ã— improvement)
3. **Monitor NIC usage** (verify all 4 NICs have traffic)
4. **Profile with nsys** (identify any remaining bottlenecks)

### Short-term (Optimization)

1. **Tune MAX_INFLIGHT_SEND** (try 14-16 instead of 12)
2. **Batch tcpx_irecv** (receive multiple chunks at once)
3. **Optimize chunk size** (experiment with 4MB, 8MB)
4. **Add topology-aware NIC selection** (GPU-NIC affinity)

### Long-term (Advanced Features)

1. **Dynamic channel adjustment** (adapt to network conditions)
2. **Load balancing** (distribute based on current NIC load)
3. **Error recovery** (handle channel failures gracefully)
4. **Multi-GPU support** (extend to 8 GPUs per node)

---

## ğŸ“š Documentation

| Document | Purpose | Status |
|----------|---------|--------|
| `MULTI_CHANNEL_DESIGN.md` | High-level architecture | âœ… Complete |
| `MULTI_CHANNEL_IMPLEMENTATION_DETAILS.md` | Implementation specs | âœ… Complete |
| `PHASE1_COMPLETE.md` | Phase 1 deliverables | âœ… Complete |
| `PHASE3_COMPLETE.md` | Phase 3 deliverables | âœ… Complete |
| `FINAL_SUMMARY.md` | Overall project summary | ğŸ”„ To be updated |

---

## ğŸ‰ Conclusion

**Phase 3 is complete and successful!**

All work is done:
- âœ… Multi-channel performance test implemented
- âœ… All debugging experience preserved
- âœ… Backward compatible
- âœ… Compiles successfully
- âœ… Ready for cloud testing

**Expected Impact**: 4Ã— bandwidth improvement (3 GB/s â†’ 12 GB/s on server)

**Next Action**: Test on GCP nodes with TCPX to verify multi-channel performance!

ğŸš€ **Let's achieve that 4Ã— bandwidth improvement!** ğŸš€

