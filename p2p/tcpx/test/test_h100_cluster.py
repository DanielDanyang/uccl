#!/usr/bin/env python3
"""
H100 é›†ç¾¤ TCPX è¿æ¥æµ‹è¯•
ä¸“é—¨æµ‹è¯•ä¸¤ä¸ª H100 èŠ‚ç‚¹ï¼ˆå„8å¼ å¡ï¼‰ä¹‹é—´çš„ TCPX è¿æ¥
èŠ‚ç‚¹1: 10.0.1.25 (8x H100)
èŠ‚ç‚¹2: 10.0.0.226 (8x H100)
"""

import argparse
import os
import sys
import time
import threading
import concurrent.futures

def import_p2p_module():
    """å¯¼å…¥ TCPX å¼•æ“æ¨¡å—"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)
    
    import importlib.util
    so_file = os.path.join(parent_dir, 'libuccl_tcpx_engine.so')
    spec = importlib.util.spec_from_file_location("p2p", so_file)
    p2p = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(p2p)
    return p2p

def run_h100_server(node_ip="10.0.1.25", base_port=12345, num_gpus=8):
    """è¿è¡Œ H100 æœåŠ¡å™¨èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹1ï¼‰"""
    print(f"ğŸ–¥ï¸  H100 æœåŠ¡å™¨èŠ‚ç‚¹å¯åŠ¨")
    print(f"ğŸ“ èŠ‚ç‚¹ IP: {node_ip}")
    print(f"ğŸ® GPU æ•°é‡: {num_gpus}")
    print(f"ğŸ”Œ ç«¯å£èŒƒå›´: {base_port}-{base_port + num_gpus - 1}")
    print("=" * 60)
    
    try:
        # å¯¼å…¥æ¨¡å—
        print("ğŸ”„ å¯¼å…¥ TCPX å¼•æ“æ¨¡å—...")
        p2p = import_p2p_module()
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # ä¸ºæ¯ä¸ª GPU åˆ›å»ºå¼•æ“
        engines = {}
        print(f"ğŸ”„ ä¸º {num_gpus} ä¸ª GPU åˆ›å»ºå¼•æ“...")
        
        for gpu_idx in range(num_gpus):
            print(f"  ğŸ”„ åˆ›å»º GPU {gpu_idx} å¼•æ“...")
            engine = p2p.Endpoint(gpu_idx, 4)
            engines[gpu_idx] = engine
            print(f"  âœ… GPU {gpu_idx} å¼•æ“åˆ›å»ºæˆåŠŸ")
        
        print(f"âœ… æ‰€æœ‰ {num_gpus} ä¸ªå¼•æ“åˆ›å»ºå®Œæˆ")
        
        # æ˜¾ç¤ºæœåŠ¡å™¨ä¿¡æ¯
        print(f"ğŸ“‹ æœåŠ¡å™¨ä¿¡æ¯:")
        for gpu_idx in range(num_gpus):
            metadata = engines[gpu_idx].get_metadata()
            port = base_port + gpu_idx
            print(f"  GPU {gpu_idx}: {node_ip}:{port} (å…ƒæ•°æ®: {len(metadata)} å­—èŠ‚)")
        
        print(f"ğŸ’¡ åœ¨å®¢æˆ·ç«¯èŠ‚ç‚¹è¿è¡Œ:")
        print(f"   python test/test_h100_cluster.py --mode client --server-ip {node_ip}")
        print()
        
        # ç­‰å¾…è¿æ¥
        connections = {}
        print(f"ğŸ”„ ç­‰å¾…æ¥è‡ªå®¢æˆ·ç«¯çš„è¿æ¥...")
        
        def accept_connection(gpu_idx):
            """ä¸ºæŒ‡å®š GPU æ¥å—è¿æ¥"""
            try:
                print(f"  ğŸ”„ GPU {gpu_idx} ç­‰å¾…è¿æ¥...")
                success, client_ip, client_gpu, conn_id = engines[gpu_idx].accept()
                
                if success:
                    print(f"  âœ… GPU {gpu_idx} æ¥å—è¿æ¥æˆåŠŸ!")
                    print(f"    å®¢æˆ·ç«¯: {client_ip} GPU {client_gpu}")
                    print(f"    è¿æ¥ ID: {conn_id}")
                    return (gpu_idx, conn_id, client_ip, client_gpu)
                else:
                    print(f"  âŒ GPU {gpu_idx} æ¥å—è¿æ¥å¤±è´¥")
                    return None
            except Exception as e:
                print(f"  âŒ GPU {gpu_idx} æ¥å—è¿æ¥å¼‚å¸¸: {e}")
                return None
        
        # å¹¶å‘æ¥å—æ‰€æœ‰è¿æ¥
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_gpus) as executor:
            futures = [executor.submit(accept_connection, gpu_idx) for gpu_idx in range(num_gpus)]
            
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    gpu_idx, conn_id, client_ip, client_gpu = result
                    connections[gpu_idx] = {
                        'conn_id': conn_id,
                        'client_ip': client_ip,
                        'client_gpu': client_gpu
                    }
        
        print(f"ğŸ“Š è¿æ¥ç»Ÿè®¡:")
        print(f"  æˆåŠŸè¿æ¥: {len(connections)}/{num_gpus}")
        
        if len(connections) > 0:
            print(f"âœ… éƒ¨åˆ†è¿æ¥å»ºç«‹æˆåŠŸï¼Œä¿æŒè¿æ¥ 30 ç§’...")
            time.sleep(30)
            print(f"âœ… æœåŠ¡å™¨æµ‹è¯•å®Œæˆ")
            return True
        else:
            print(f"âŒ æ²¡æœ‰æˆåŠŸçš„è¿æ¥")
            return False
            
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_h100_client(server_ip="10.0.1.25", base_port=12345, num_gpus=8):
    """è¿è¡Œ H100 å®¢æˆ·ç«¯èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹2ï¼‰"""
    print(f"ğŸ’» H100 å®¢æˆ·ç«¯èŠ‚ç‚¹å¯åŠ¨")
    print(f"ğŸ¯ ç›®æ ‡æœåŠ¡å™¨: {server_ip}")
    print(f"ğŸ® GPU æ•°é‡: {num_gpus}")
    print(f"ğŸ”Œ ç›®æ ‡ç«¯å£èŒƒå›´: {base_port}-{base_port + num_gpus - 1}")
    print("=" * 60)
    
    try:
        # å¯¼å…¥æ¨¡å—
        print("ğŸ”„ å¯¼å…¥ TCPX å¼•æ“æ¨¡å—...")
        p2p = import_p2p_module()
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # ä¸ºæ¯ä¸ª GPU åˆ›å»ºå¼•æ“
        engines = {}
        print(f"ğŸ”„ ä¸º {num_gpus} ä¸ª GPU åˆ›å»ºå¼•æ“...")
        
        for gpu_idx in range(num_gpus):
            print(f"  ğŸ”„ åˆ›å»º GPU {gpu_idx} å¼•æ“...")
            engine = p2p.Endpoint(gpu_idx, 4)
            engines[gpu_idx] = engine
            print(f"  âœ… GPU {gpu_idx} å¼•æ“åˆ›å»ºæˆåŠŸ")
        
        print(f"âœ… æ‰€æœ‰ {num_gpus} ä¸ªå¼•æ“åˆ›å»ºå®Œæˆ")
        
        # ç­‰å¾…æœåŠ¡å™¨å‡†å¤‡
        print("ğŸ”„ ç­‰å¾… 5 ç§’è®©æœåŠ¡å™¨å‡†å¤‡...")
        time.sleep(5)
        
        # è¿æ¥åˆ°æœåŠ¡å™¨
        connections = {}
        print(f"ğŸ”„ è¿æ¥åˆ°æœåŠ¡å™¨çš„æ‰€æœ‰ GPU...")
        
        def connect_to_server(gpu_idx):
            """è¿æ¥åˆ°æœåŠ¡å™¨çš„æŒ‡å®š GPU"""
            try:
                server_port = base_port + gpu_idx
                print(f"  ğŸ”„ GPU {gpu_idx} è¿æ¥åˆ° {server_ip}:{server_port}...")
                
                success, conn_id = engines[gpu_idx].connect(server_ip, gpu_idx, server_port)
                
                if success:
                    print(f"  âœ… GPU {gpu_idx} è¿æ¥æˆåŠŸ! conn_id = {conn_id}")
                    return (gpu_idx, conn_id)
                else:
                    print(f"  âŒ GPU {gpu_idx} è¿æ¥å¤±è´¥")
                    return None
            except Exception as e:
                print(f"  âŒ GPU {gpu_idx} è¿æ¥å¼‚å¸¸: {e}")
                return None
        
        # å¹¶å‘è¿æ¥æ‰€æœ‰ GPU
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_gpus) as executor:
            futures = [executor.submit(connect_to_server, gpu_idx) for gpu_idx in range(num_gpus)]
            
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    gpu_idx, conn_id = result
                    connections[gpu_idx] = conn_id
        
        print(f"ğŸ“Š è¿æ¥ç»Ÿè®¡:")
        print(f"  æˆåŠŸè¿æ¥: {len(connections)}/{num_gpus}")
        
        if len(connections) > 0:
            print(f"âœ… éƒ¨åˆ†è¿æ¥å»ºç«‹æˆåŠŸï¼Œä¿æŒè¿æ¥ 30 ç§’...")
            time.sleep(30)
            print(f"âœ… å®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ")
            return True
        else:
            print(f"âŒ æ²¡æœ‰æˆåŠŸçš„è¿æ¥")
            return False
            
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='H100 é›†ç¾¤ TCPX è¿æ¥æµ‹è¯•')
    parser.add_argument('--mode', choices=['server', 'client'], 
                       required=True, help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--server-ip', default='10.0.1.25',
                       help='æœåŠ¡å™¨ IP åœ°å€')
    parser.add_argument('--base-port', type=int, default=12345,
                       help='åŸºç¡€ç«¯å£å·')
    parser.add_argument('--num-gpus', type=int, default=8,
                       help='GPU æ•°é‡')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ H100 é›†ç¾¤ TCPX è¿æ¥æµ‹è¯•")
    print(f"ğŸ”§ é…ç½®:")
    print(f"  æ¨¡å¼: {args.mode}")
    print(f"  æœåŠ¡å™¨ IP: {args.server_ip}")
    print(f"  åŸºç¡€ç«¯å£: {args.base_port}")
    print(f"  GPU æ•°é‡: {args.num_gpus}")
    print()
    
    if args.mode == 'server':
        success = run_h100_server(args.server_ip, args.base_port, args.num_gpus)
    else:  # client
        success = run_h100_client(args.server_ip, args.base_port, args.num_gpus)
    
    if success:
        print(f"\nğŸ‰ H100 é›†ç¾¤ TCPX è¿æ¥æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“‹ éªŒè¯äº†:")
        print(f"  âœ… è·¨èŠ‚ç‚¹çš„çœŸå® TCPX è¿æ¥")
        print(f"  âœ… å¤š GPU å¹¶å‘è¿æ¥")
        print(f"  âœ… H100 é›†ç¾¤é€šä¿¡èƒ½åŠ›")
        print(f"  âœ… TCPX ä½œä¸º RDMA æ›¿ä»£æ–¹æ¡ˆ")
    else:
        print(f"\nâŒ H100 é›†ç¾¤ TCPX è¿æ¥æµ‹è¯•å¤±è´¥")
        print(f"ğŸ”§ å¯èƒ½çš„é—®é¢˜:")
        print(f"  - ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆæ£€æŸ¥ 10.0.1.25 â†” 10.0.0.226ï¼‰")
        print(f"  - TCPX æ’ä»¶é…ç½®é—®é¢˜")
        print(f"  - ç«¯å£è¢«å ç”¨æˆ–é˜²ç«å¢™é˜»æ­¢")
        print(f"  - GPU è®¾å¤‡è®¿é—®æƒé™é—®é¢˜")
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
